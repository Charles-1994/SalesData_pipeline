{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c908eeea-381b-4eaf-9a6a-9014a9cc0aeb",
   "metadata": {},
   "source": [
    "## Sales Data Exploration\n",
    "\n",
    "Given sales data of a retail company. We have data for the year 2019 for every month.\n",
    "\n",
    "data format: **csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2081c9-2089-449e-8fde-db6f9f44f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# spark packages\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, count, when, desc, sum, round, to_timestamp, max as max_, row_number, year, month\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590a582e-5398-4a42-983c-b04fed6e2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "def create_spark_session(app_name: str = \"SalesIngestion\") -> SparkSession:\n",
    "    builder = SparkSession.builder.appName(app_name) \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    \n",
    "    # This function wraps your SparkSession with Delta Lake capabilities.\n",
    "    spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49c603-cbf8-4d1a-bba2-663196d0e56f",
   "metadata": {},
   "source": [
    "### Understand the different columns with in the given data and also the schema that can be infered from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086a3738-c3ce-4e73-94f7-f722c3ab8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dfa6edf-42c9-4ca6-83fb-7026988c963b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales_Data\\Sales_April_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_August_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_December_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_February_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_January_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_July_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_June_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_March_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_May_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_November_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_October_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "Sales_Data\\Sales_September_2019.csv\n",
      "6\n",
      "\n",
      "root\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Sales_Data\"\n",
    "\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "for file in csv_files:\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(file)\n",
    "    print(file)\n",
    "    print(len(df.columns))\n",
    "    print()\n",
    "    df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e153a52-5038-441d-9d54-233e3f0997a5",
   "metadata": {},
   "source": [
    "### Assumption 1:\n",
    "For a Sales transaction, Order ID should not be nullable. similarly, Each order should atleast have a product with non zero quantity. similarly, for each order, the date should be recorded. \n",
    "\n",
    "So, the Order ID, Product, Quantity Ordered, Order Date should not have null values.\n",
    "\n",
    "While Purchase address can be null and Price can be 0 (possible)\n",
    "\n",
    "and Ideal schema should be\n",
    "\n",
    "root\n",
    "\n",
    "* |-- **Order ID**: integer (nullable = False)\n",
    "* |-- **Product**: string (nullable = False)\n",
    "* |-- **Quantity Ordered**: integer (nullable = False)\n",
    "* |-- **Price Each**: double (nullable = true)\n",
    "* |-- **Order Date**: timestamp (nullable = False)\n",
    "* |-- **Purchase Address**: string (nullable = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887e94e-cd44-4266-b2b3-a284feb7eec9",
   "metadata": {},
   "source": [
    "### Exploring a single csv file to understand more about the data we are handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ab205b-336a-4d91-b753-fa0d3fa5a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+-------------------+------------------+--------------+----------------------------------+\n",
      "|summary|Order ID          |Product     |Quantity Ordered   |Price Each        |Order Date    |Purchase Address                  |\n",
      "+-------+------------------+------------+-------------------+------------------+--------------+----------------------------------+\n",
      "|count  |11629             |11646       |11629              |11629             |11646         |11646                             |\n",
      "|mean   |253751.81442944362|NULL        |1.1281279559721387 |179.40000687934585|NULL          |NULL                              |\n",
      "|stddev |3235.175358525277 |NULL        |0.43507719933866423|328.59504155699716|NULL          |NULL                              |\n",
      "|min    |248151            |20in Monitor|1                  |2.99              |09/01/19 05:10|1 11th St, San Francisco, CA 94016|\n",
      "|max    |259357            |iPhone      |6                  |1700.0            |Order Date    |Purchase Address                  |\n",
      "+-------+------------------+------------+-------------------+------------------+--------------+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16bc8c-340e-4bec-a799-e409cf39bb69",
   "metadata": {},
   "source": [
    "### Checking for Null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edceabbf-1c75-47c6-923e-22697ca6de9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|Order ID|Product|Quantity Ordered|Price Each|Order Date|Purchase Address|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|      57|     40|              57|        57|        40|              40|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of null values in each column\n",
    "null_count = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "null_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2102c6d8-818e-4102-a848-ad8e841cf5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|Order ID|Product|Quantity Ordered|Price Each|Order Date|Purchase Address|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|Product|            NULL|      NULL|Order Date|Purchase Address|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|Product|            NULL|      NULL|Order Date|Purchase Address|\n",
      "|    NULL|Product|            NULL|      NULL|Order Date|Purchase Address|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|Product|            NULL|      NULL|Order Date|Purchase Address|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col('Order ID').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccc965c-e82d-4acb-b07b-8cd92880d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|Order ID|Product|Quantity Ordered|Price Each|Order Date|Purchase Address|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "|    NULL|   NULL|            NULL|      NULL|      NULL|            NULL|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col('Product').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20541d0-4e70-411a-a1e4-34fe68bb0185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|Order ID|Product|Quantity Ordered|Price Each|Order Date|Purchase Address|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|       0|      0|               0|         0|         0|               0|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of null values in each column after filtering by Order ID\n",
    "null_count = df.filter(col('Order ID').isNotNull()).select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "null_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0c805-22fd-4782-bdde-88c4c6834252",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* There are null values in each columns.\n",
    "* Product, Order Date and Purchase Address have some false values or garbage values. all these records have Order Id as NUll.\n",
    "\n",
    "As per the assumption, for any sales transaction, Order Id should not be null. Hence removing the records with Order ID = Null\n",
    "\n",
    "Seems like the removing the records which have Order ID = Null cleans all the records with null values in other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9451427-24cd-4e66-9cc7-4ada4b9bee32",
   "metadata": {},
   "source": [
    "### Checking for Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "391cac7a-2f46-4dae-9573-9530e916c301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11629\n",
      "11611\n",
      "11610\n"
     ]
    }
   ],
   "source": [
    "df1 =  df.filter(col('Order ID').isNotNull())\n",
    "print(df1.count())\n",
    "print(df1.distinct().count())\n",
    "print(df1.select(['Order ID', 'Product']).distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ce4fd0-dd6c-4a59-9406-3f3c1ce4991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----+\n",
      "|Order ID|             Product|count|\n",
      "+--------+--------------------+-----+\n",
      "|  250174|Apple Airpods Hea...|    2|\n",
      "|  253981|Lightning Chargin...|    2|\n",
      "|  256196|USB-C Charging Cable|    2|\n",
      "|  256588|Apple Airpods Hea...|    2|\n",
      "|  249895|34in Ultrawide Mo...|    2|\n",
      "|  252537|    Wired Headphones|    2|\n",
      "|  259296|Apple Airpods Hea...|    2|\n",
      "|  249910|AAA Batteries (4-...|    2|\n",
      "|  251220|    Wired Headphones|    2|\n",
      "|  259297|Lightning Chargin...|    2|\n",
      "|  258715|Lightning Chargin...|    2|\n",
      "|  259035|    27in FHD Monitor|    2|\n",
      "|  248787|AA Batteries (4-p...|    2|\n",
      "|  257530|USB-C Charging Cable|    2|\n",
      "|  248171|USB-C Charging Cable|    2|\n",
      "|  255390|Lightning Chargin...|    2|\n",
      "|  256763|    27in FHD Monitor|    2|\n",
      "|  254945|Apple Airpods Hea...|    2|\n",
      "|  255318|  Macbook Pro Laptop|    2|\n",
      "|  248234|34in Ultrawide Mo...|    1|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy(['Order ID', 'Product']).count().sort(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fc4f93a-eae3-486e-9b75-2a322461efa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------------+----------+--------------+--------------------+\n",
      "|Order ID|         Product|Quantity Ordered|Price Each|    Order Date|    Purchase Address|\n",
      "+--------+----------------+----------------+----------+--------------+--------------------+\n",
      "|  251220|Wired Headphones|               2|     11.99|09/17/19 05:49|153 Meadow St, Po...|\n",
      "|  251220|Wired Headphones|               1|     11.99|09/17/19 05:49|153 Meadow St, Po...|\n",
      "+--------+----------------+----------------+----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter((col('Order ID')== 251220)&(col('Product')=='Wired Headphones')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216cf85-e6d2-42f7-bdac-25b710a4e88d",
   "metadata": {},
   "source": [
    "in the above records, we can observe that\n",
    "* there are atleast (11629 - 11611) = 18 duplicate values in the data set\n",
    "* for some records, every thing is same except for Quantity ordered. \n",
    "\n",
    "### Assumption 2: \n",
    "Multiple Products can be order with in one Order Id and have two records with Order ID with different products. Order ID belonging to one Product should have only 1 record at an Order Date time. \n",
    "\n",
    "As per the above assumption, the above could not be possible.\n",
    "\n",
    "Hence, only taking the max value (Quantity Ordered) record of the above two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6321bad-f0b8-4fba-ba5f-7348d7b37f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup = df1.distinct()\n",
    "\n",
    "# Define the window specification\n",
    "windowSpec = Window.partitionBy(\"Order ID\", \"Product\").orderBy(desc(\"Quantity Ordered\"))\n",
    "\n",
    "# Apply the window function and filter the results\n",
    "df_dedup = df_dedup.withColumn(\"row_number\", row_number().over(windowSpec)) \\\n",
    "             .filter(col(\"row_number\") == 1) \\\n",
    "             .drop(\"row_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "772550cf-7f84-466f-bf2c-9300bb617f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------------+----------+--------------+--------------------+\n",
      "|Order ID|         Product|Quantity Ordered|Price Each|    Order Date|    Purchase Address|\n",
      "+--------+----------------+----------------+----------+--------------+--------------------+\n",
      "|  251220|Wired Headphones|               2|     11.99|09/17/19 05:49|153 Meadow St, Po...|\n",
      "+--------+----------------+----------------+----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dedup.filter((col('Order ID')== 251220)&(col('Product')=='Wired Headphones')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3836dd7a-c860-44a2-8439-52fcf308681d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dedup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_dedup\u001b[49m\u001b[38;5;241m.\u001b[39mgroupBy([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39msort(desc(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_dedup' is not defined"
     ]
    }
   ],
   "source": [
    "df_dedup.groupBy(['Order ID', 'Product']).count().sort(desc('count')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6776f-5bd3-4a6f-8134-0a112aebb497",
   "metadata": {},
   "source": [
    "These above operations of handling null values, duplicates and invalid records must be done on each data set and form a single data fram before saving into the suitable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90410a-a273-4508-8d76-ea747a89a5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f780da5-7f6d-427d-8ade-b5df260c1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f91eba-baed-42c5-9fea-d657f9a23023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
